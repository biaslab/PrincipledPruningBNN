# Principled Pruning of Bayesian Neural Networks through Variational Free Energy Minimization
*By Jim Beckers, Bart van Erp, Ziyue Zhao, Kirill Kondrashov and Bert de Vries*
### Available on Arxiv
---
**Abstract**

The Bayesian approach to neural network training provides a principled way of updating beliefs about model parameters for a given set of observations. Moreover, Bayesian neural network training supports straightforward solutions to many important problems in today's machine learning research threads, such as federated learning, continual learning, and network compression. This paper focuses on the latter problem. We introduce an iterative training-pruning scheme that is completely based on variational free energy minimization. Importantly, the pruning scheme has a clear stopping criterion and minimizes the same objective that is used during training. Our approach is validated for different probabilistic inference algorithms on various UCI data sets and achieves better model performance in comparison to state-of-the-art pruning schemes.

---
This repository contains all experiments of the paper.
